{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPczOgR4af6V6pkTRVVMnAh"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **PyTorch Card Classifier**\n",
        "\n",
        "We will tackle using PyTorch by focusing on these 3 parts:\n",
        "\n",
        "\n",
        "*   How to use PyTorch datasets and data loaders\n",
        "*   How to set up the PyTorch model based on NN\n",
        "*   How to set up the PyTorch training loop\n",
        "\n"
      ],
      "metadata": {
        "id": "Zxu8PO-U0wIu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "zip_path = \"archive.zip\"\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"cards_classifier_model_data\")"
      ],
      "metadata": {
        "id": "XKr3WyoE4b6a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TfPZp1CVz89X"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "import timm\n",
        "\n",
        "import matplotlib.pyplot as plt # For data viz\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sys\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "TRAIN_DIR = '/content/cards_classifier_model_data/train'\n",
        "TEST_DIR = '/content/cards_classifier_model_data/test'\n",
        "VALID_DIR = '/content/cards_classifier_model_data/valid'\n",
        "\n",
        "print('System Version:', sys.version)\n",
        "print('PyTorch version', torch.__version__)\n",
        "print('Torchvision version', torchvision.__version__)\n",
        "print('Numpy version', np.__version__)\n",
        "print('Pandas version', pd.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1. Setting up the dataset"
      ],
      "metadata": {
        "id": "6vrzzqtAAkIh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PlayingCardDataset(Dataset):\n",
        "    def __init__(self, data_dir, transform=None):\n",
        "        self.data = ImageFolder(data_dir, transform=transform)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx]\n",
        "\n",
        "    @property\n",
        "    def classes(self):\n",
        "        return self.data.classes"
      ],
      "metadata": {
        "id": "36dzyqyv0eXw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = PlayingCardDataset(\n",
        "    data_dir=TRAIN_DIR\n",
        ")\n",
        "len(dataset)"
      ],
      "metadata": {
        "id": "7xrzNePf5dg8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image, label = dataset[6000]\n",
        "print(label)\n",
        "image"
      ],
      "metadata": {
        "id": "ls9l6B_B60Ur"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a dictionary associating target values with folder names\n",
        "target_to_class = {v: k for k, v in ImageFolder(TRAIN_DIR).class_to_idx.items()}\n",
        "print(target_to_class)"
      ],
      "metadata": {
        "id": "VojG0mEN625v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((128, 128)), # convert all images to the same size for the NN input layer\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "dataset = PlayingCardDataset(TRAIN_DIR, transform)"
      ],
      "metadata": {
        "id": "6bJwZieL65Sc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image, label = dataset[100]\n",
        "image.shape"
      ],
      "metadata": {
        "id": "ZJD0K5g-7TlO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DataLoader in PyTorch is used to efficiently feed data to the model during training so it's faster\n",
        "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
        "for images, labels in dataloader:\n",
        "  break\n",
        "images.shape, labels.shape"
      ],
      "metadata": {
        "id": "cqg0YxTh8XBE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2. Pytorch Model\n",
        "Pytorch datasets have a structured way of organizing your data, pytorch models follow a similar paradigm.\n",
        "\n",
        "\n",
        "*   We could create the model from scratch defining each layer. However for tasks like image classification, many of the state of the art architectures are readily available and we can import them from packages like timm.\n",
        "*   Understanding the pytorch model is all about understanding the shape the data is at each layer, and the main one we need to modify for a task is the final layer.\n",
        "* Here we have 53 targets, so we will modify the last layer for this.\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "In TensorFlow/Keras, especially with the Sequential API, you usually define everything in one place: the pretrained backbone, flattening, and new classifier layers all in a single Sequential list.\n",
        "\n",
        "PyTorch separates layer definition (__init__) from layer connection / forward pass (forward). That’s why here you have:\n",
        "\n",
        "* self.base_model – holds the entire pretrained model.\n",
        "* self.features – extracts only the backbone layers you want.\n",
        "* self.classifier – your new head.\n",
        "\n",
        "You then explicitly connect them in forward. In Keras, that separation is optional because the framework can automatically chain layers if you use Sequential, or you can use the Functional API for explicit control."
      ],
      "metadata": {
        "id": "8ew37xzUAI3Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleCardClassifer(nn.Module):\n",
        "    def __init__(self, num_classes=53):\n",
        "        super(SimpleCardClassifer, self).__init__()\n",
        "        # Load a pretrained EfficientNet-B0 model from timm\n",
        "        self.base_model = timm.create_model('efficientnet_b0', pretrained=True)\n",
        "\n",
        "        # Take all layers of the EfficientNet except the last classification layer.\n",
        "        # The last layer was trained for ImageNet (1000 classes), so we remove it to replace with our own.\n",
        "        # This part extracts features from images (edges, textures, shapes, etc.).\n",
        "        self.features = nn.Sequential(*list(self.base_model.children())[:-1])\n",
        "\n",
        "        # EfficientNet-B0 produces a 1280-dimensional feature vector at the end\n",
        "        enet_out_size = 1280\n",
        "\n",
        "        # Define the classifier head:\n",
        "        # - Flatten: convert feature map into a single vector\n",
        "        # - Linear: map the 1280 features to `num_classes` outputs (one score per class)\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(enet_out_size, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Defines how input data flows through the model (the \"forward pass\")\n",
        "        # This is required in PyTorch to connect the layers; unlike Keras Sequential API,\n",
        "        # PyTorch does not automatically chain layers.\n",
        "        x = self.features(x)      # Extract features using the pretrained backbone\n",
        "        output = self.classifier(x)  # Map features to class scores with the new linear layer\n",
        "        return output\n"
      ],
      "metadata": {
        "id": "l672EOcx8b3v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SimpleCardClassifer(num_classes=53)\n",
        "print(str(model)[:500])"
      ],
      "metadata": {
        "id": "28uf_vHrAykY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_out = model(images)\n",
        "example_out.shape # [batch_size, num_classes]"
      ],
      "metadata": {
        "id": "xRHR1HjvQ6SD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 3. Training Loop"
      ],
      "metadata": {
        "id": "5ACM-9vHRM4E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# Optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "hMgoyUfcRHWj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((128, 128)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "train_dataset = PlayingCardDataset(TRAIN_DIR, transform=transform)\n",
        "val_dataset = PlayingCardDataset(VALID_DIR, transform=transform)\n",
        "test_dataset = PlayingCardDataset(TEST_DIR, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "test_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "RoTNqkosRRiE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Simple training loop for PyTorch model - note in TF you don't do any of these manual steps (use .fit())\n",
        "num_epochs = 5\n",
        "train_losses, val_losses = [], []  # Lists to store loss history\n",
        "\n",
        "# Set device to GPU if available, else CPU\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Initialize the model and move it to the device\n",
        "model = SimpleCardClassifer(num_classes=53)\n",
        "model.to(device)\n",
        "\n",
        "# Define the loss function (Cross-Entropy for multi-class classification)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Define the optimizer (Adam) with learning rate 0.001\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    # ------------------------\n",
        "    # Training phase\n",
        "    # ------------------------\n",
        "    model.train()  # Set model to training mode (enables dropout, batchnorm updates)\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for images, labels in tqdm(train_loader, desc='Training loop'):\n",
        "        # Move input images and labels to the device\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()       # Clear previous gradients\n",
        "        outputs = model(images)     # Forward pass: compute model predictions\n",
        "        loss = criterion(outputs, labels)  # Compute loss\n",
        "        loss.backward()             # Backpropagation: compute gradients\n",
        "        optimizer.step()            # Update weights using optimizer\n",
        "        running_loss += loss.item() * labels.size(0)  # Accumulate total loss for the epoch\n",
        "\n",
        "    # Average training loss over all training samples\n",
        "    train_loss = running_loss / len(train_loader.dataset)\n",
        "    train_losses.append(train_loss)\n",
        "\n",
        "    # ------------------------\n",
        "    # Validation phase\n",
        "    # ------------------------\n",
        "    model.eval()  # Set model to evaluation mode (disables dropout, batchnorm updates)\n",
        "    running_loss = 0.0\n",
        "    with torch.no_grad():  # No gradient computation needed for validation\n",
        "        for images, labels in tqdm(val_loader, desc='Validation loop'):\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)             # Forward pass\n",
        "            loss = criterion(outputs, labels)  # Compute validation loss\n",
        "            running_loss += loss.item() * labels.size(0)\n",
        "\n",
        "    # Average validation loss over all validation samples\n",
        "    val_loss = running_loss / len(val_loader.dataset)\n",
        "    val_losses.append(val_loss)\n",
        "\n",
        "    # Print losses for this epoch\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs} - Train loss: {train_loss}, Validation loss: {val_loss}\")\n"
      ],
      "metadata": {
        "id": "rxxhSTt-Rk76"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(train_losses, label='Training loss')\n",
        "plt.plot(val_losses, label='Validation loss')\n",
        "plt.legend()\n",
        "plt.title(\"Loss over epochs\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hR91yTgcR91S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Load and preprocess the image\n",
        "def preprocess_image(image_path, transform):\n",
        "    image = Image.open(image_path).convert(\"RGB\")\n",
        "    return image, transform(image).unsqueeze(0)\n",
        "\n",
        "# Predict using the model\n",
        "def predict(model, image_tensor, device):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        image_tensor = image_tensor.to(device)\n",
        "        outputs = model(image_tensor)\n",
        "        probabilities = torch.nn.functional.softmax(outputs, dim=1)\n",
        "    return probabilities.cpu().numpy().flatten()\n",
        "\n",
        "# Visualization\n",
        "def visualize_predictions(original_image, probabilities, class_names):\n",
        "    fig, axarr = plt.subplots(1, 2, figsize=(14, 7))\n",
        "\n",
        "    # Display image\n",
        "    axarr[0].imshow(original_image)\n",
        "    axarr[0].axis(\"off\")\n",
        "\n",
        "    # Display predictions\n",
        "    axarr[1].barh(class_names, probabilities)\n",
        "    axarr[1].set_xlabel(\"Probability\")\n",
        "    axarr[1].set_title(\"Class Predictions\")\n",
        "    axarr[1].set_xlim(0, 1)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Example usage\n",
        "test_image = f\"{TEST_DIR}/five of diamonds/2.jpg\"\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((128, 128)),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "original_image, image_tensor = preprocess_image(test_image, transform)\n",
        "probabilities = predict(model, image_tensor, device)\n",
        "\n",
        "# Assuming dataset.classes gives the class names\n",
        "class_names = dataset.classes\n",
        "visualize_predictions(original_image, probabilities, class_names)"
      ],
      "metadata": {
        "id": "V0esdikBTwHc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jDI0zlO3UT9-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}